{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Azure Machine Learning Data assets\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](/sdk/resources/workspace/workspace.ipynb) \n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](/sdk/README.md#getting-started)\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Create Azure Machine Learning `Data` from Python SDK for\n",
    "  - Local files and folders\n",
    "  - Remote files and folders\n",
    "- Use data in a CommandJob\n",
    "\n",
    "**Motivations** - Azure Machine Learning `data` assets are references to file(s) or folder in local or remote storage along with any corresponding metadata. They are not copies of your data. You can use these data assets to access relevant data during model training and mount or download the referenced data to your compute target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from azure.ml import MLClient\n",
    "from azure.ml.entities import Data, CommandJob, JobInput\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from azure.ml._constants import AssetTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [interactive authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.interactivebrowsercredential?view=azure-python) for this tutorial. More advanced connection methods can be found [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter details of your AML workspace\n",
    "subscription_id = '<SUBSCRIPTION_ID>'\n",
    "resource_group = '<RESOURCE_GROUP>'\n",
    "workspace = '<AML_WORKSPACE_NAME>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a handle to the workspace\n",
    "ml_client = MLClient(InteractiveBrowserCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create data asset\n",
    "In this section we will create data from various locations\n",
    "\n",
    "## 2.1 Configuring data asset\n",
    "The Data class allows user to configure the the following key aspects. \n",
    "- `name` - Name of the data asset in the workspace\n",
    "- `type` - The type of data being referred to. Allowed values are `uri_file` and `uri_folder`. The default is `uri_folder`.\n",
    "- `path` - The path to the file or folder. These can be local or remote files or folders. For remote files - http/https, wasb are supported.\n",
    "- `version` - Version of the data asset. If omitted, Azure ML will autogenerate a version.\n",
    "- `description` - Description of the data asset.\n",
    "\n",
    "## 2.2 Create data asset from a local file or folder\n",
    "Let us use `Data` to create a data asset from a local file and folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a local file\n",
    "local_dataset = Data(\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    path=\"./data/titanic.csv\", \n",
    "    name=\"local-file-example\", \n",
    "    description=\"Dataset created from local file.\")\n",
    "\n",
    "ml_client.data.create_or_update(local_dataset)\n",
    "\n",
    "# Use a local folder\n",
    "local_folder_dataset = Data(\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    path=\"./data\",\n",
    "    name=\"local-folder-example\", \n",
    "    description=\"Dataset created from local folder.\")\n",
    "\n",
    "ml_client.data.create_or_update(local_folder_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Create data asset from files or folders in the cloud\n",
    "Let us use `Data` to create a data asset from remote locations. Supported remote locations are http/https, wasb and azureml locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset from a file in the aml workspace\n",
    "cloud_ds_aml_file = Data(\n",
    "    path=\"azureml://datastores/workspaceblobstore/paths/example-data/titanic.csv\",\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    name=\"cloud-file-example\",\n",
    "    description=\"Dataset created from file in cloud.\"\n",
    ")\n",
    "ml_client.data.create_or_update(cloud_ds_aml_file)\n",
    "\n",
    "#create dataset from a public file with hhtps URL\n",
    "cloud_ds_file = Data(\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    path=\"https://azuremlexamples.blob.core.windows.net/datasets/titanic.csv\",\n",
    "    name=\"public-file-https-example\",\n",
    "    description=\"Dataset created from a publicly available file using https URL.\"\n",
    ")\n",
    "ml_client.data.create_or_update(cloud_ds_file)\n",
    "\n",
    "#Create dataset from a folder in the cloud\n",
    "cloud_ds_folder = Data(\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    path=\"https://mainstorage9c05dabf5c924.blob.core.windows.net/azureml-blobstore-54887b46-3cb0-485b-bb15-62e7b5578ee6/example-data/\",\n",
    "    name=\"cloud-folder-https-example\",\n",
    "    description=\"Dataset created from folder in cloud using https URL.\"\n",
    ")\n",
    "ml_client.data.create_or_update(cloud_ds_folder)\n",
    "\n",
    "#Create a dataset from a file with wasbs URL\n",
    "cloud_ds_wasbs_file = Data(\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    path=\"wasbs://mainstorage9c05dabf5c924.blob.core.windows.net/azureml-blobstore-54887b46-3cb0-485b-bb15-62e7b5578ee6/example-data/titanic.csv\",\n",
    "    name=\"cloud-file-wasbs-example\",\n",
    "    description=\"Dataset created from a file in cloud using wasbs URL.\"\n",
    ")\n",
    "ml_client.data.create_or_update(cloud_ds_wasbs_file)\n",
    "\n",
    "#Create a dataset from a folder with wasbs URL\n",
    "cloud_ds_wasbs_folder = Data(\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    path=\"wasbs://mainstorage9c05dabf5c924.blob.core.windows.net/azureml-blobstore-54887b46-3cb0-485b-bb15-62e7b5578ee6/example-data/\",\n",
    "    name=\"cloud-folder-wasbs-example\",\n",
    "    description=\"Dataset created from folder in cloud using wasbs URL.\"\n",
    ")\n",
    "ml_client.data.create_or_update(cloud_ds_wasbs_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use data asset in a Job\n",
    "You can now use any of the above data assets in a job (or a pipeline).\n",
    "\n",
    "To illustrate, let us use the data asset `public-file-https-example` in a `CommandJob`. We will look for a file _titanic.csv_ in the `dataset`, and print out the column names and number of rows in the file.\n",
    "\n",
    "## 3.1 Configure the CommandJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the command job\n",
    "job = CommandJob(\n",
    "    code=\"./src\", #local path where the code is stored\n",
    "    command= 'python main.py --input-dataset ${{inputs.input_dataset}}',\n",
    "    inputs={\"input_dataset\": JobInput(type=AssetTypes.URI_FOLDER, path=\"public-file-https-example:1\")},\n",
    "    #inputs={\"input_dataset\":JobInput(dataset=\"public-file-https-example:1\")},\n",
    "    environment= \"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:9\",\n",
    "    compute = \"cpu-cluster\", #replace this with compute in your workspace\n",
    "    display_name=\"use-dataset-in-a-job\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run the CommandJob\n",
    "Using the `MLClient` created earlier, we will now run this CommandJob in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit the command job\n",
    "returned_job = ml_client.jobs.create_or_update(job)\n",
    "#get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66962d4c952b5ba37638a017d6cc83bab37d76f69b13c17d86b9f71233a0aa71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
