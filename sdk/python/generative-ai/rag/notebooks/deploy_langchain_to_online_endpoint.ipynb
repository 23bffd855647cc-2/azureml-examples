{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install mlflow>=2.5.0\n",
    "%pip install langchain\n",
    "%pip install --extra-index-url=https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/ azure-search-documents==11.4.0a20230509004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "import openai\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.loading import load_chain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SETTING ENVIRONMENT VARIABLES_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting openai creds as env vars\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://<azure-openai-endpoint-name>.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<azure-openai-api-key>\"\n",
    "\n",
    "# setting acs creds as env vars\n",
    "os.environ[\"VECTOR_STORE_ADDRESS\"] = \"https://<azure-search-endpoint>.search.windows.net\"\n",
    "os.environ[\"VECTOR_STORE_PASSWORD\"] = \"<azure-search-key>\"\n",
    "os.environ[\"INDEX_NAME\"] = \"<azure-search-index-name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the embeddings\n",
    "def load_embeddings():\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        deployment=\"text-embedding-ada-002\",\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        chunk_size=1,\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# function to load the vectorstore\n",
    "def load_vectorstore(embeddings):\n",
    "    # using azure cognitive search as the vector store\n",
    "    vectorstore = AzureSearch(\n",
    "        azure_search_endpoint=os.getenv(\"VECTOR_STORE_ADDRESS\"),\n",
    "        azure_search_key=os.getenv(\"VECTOR_STORE_PASSWORD\"),\n",
    "        index_name=os.getenv(\"INDEX_NAME\"),\n",
    "        embedding_function=embeddings.embed_query,\n",
    "    )\n",
    "    return vectorstore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ADDING TEXTS AND METADATA TO THE VECTORSTORE_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"./stateoftheunion.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store = load_vectorstore(load_embeddings())\n",
    "_ = vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SAVING THE MODEL_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The president said that Ketanji Brown Jackson is one of our nation's top legal minds and that she will continue Justice Breyerâ€™s legacy of excellence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RM\\.conda\\envs\\aml-lc_env\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\RM\\.conda\\envs\\aml-lc_env\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"text-davinci-003\",\n",
    ")\n",
    "local_dir = \"./mlflow_model\"\n",
    "\n",
    "# creating the retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=vector_store.as_retriever()\n",
    ")\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "answer = qa.run(query)\n",
    "print(answer)\n",
    "\n",
    "# function to load the retreiver\n",
    "def load_retriever(persist_dir):\n",
    "    embeddings = load_embeddings()\n",
    "\n",
    "    vectorstore = load_vectorstore(embeddings)\n",
    "\n",
    "    # returning the retriever object\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "# saving the model\n",
    "saved_model = mlflow.langchain.save_model(\n",
    "    qa,\n",
    "    local_dir,\n",
    "    loader_fn=load_retriever,\n",
    "    extra_pip_requirements=[\n",
    "        \"--extra-index-url=https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/ azure-search-documents==11.4.0a20230509004\",\n",
    "        \"mlflow>=2.5.0\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_LOADING THE MODEL_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds and that she will continue Justice Breyer's legacy of excellence.\"]\n"
     ]
    }
   ],
   "source": [
    "model: RetrievalQA = mlflow.pyfunc.load_model(local_dir)\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "input_row = {\"query\": query}\n",
    "answer = model.predict([input_row])\n",
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Below is the code to deploy the model in azureml_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_CREATING AN INSTANCE OF MLCLIENT_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
    "print(ml_client)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_REGISTERING THE MODEL_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading mlflow_model (0.0 MBs): 100%|##########| 4317/4317 [00:02<00:00, 1697.71it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "model_name = \"aml-langchain-model\"\n",
    "model_local_path = \"./mlflow_model\"\n",
    "model = ml_client.models.create_or_update(\n",
    "    Model(name=model_name, path=model_local_path, type=AssetTypes.MLFLOW_MODEL)\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SETTING UP ENVIRONMENT VARIABLES FOR OPENAI AND AZURE COGNITIVE SEARCH_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_env_vars = {\n",
    "    \"OPENAI_API_TYPE\": os.getenv(\"OPENAI_API_TYPE\"),\n",
    "    \"OPENAI_API_VERSION\": os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    \"OPENAI_API_BASE\": os.getenv(\"OPENAI_API_BASE\") ,\n",
    "    \"OPENAI_API_KEY\": os.getenv(\"OPENAI_API_KEY\")\n",
    "}\n",
    "\n",
    "acs_env_vars = {\n",
    "    \"VECTOR_STORE_ADDRESS\": os.getenv(\"VECTOR_STORE_ADDRESS\"),\n",
    "    \"VECTOR_STORE_PASSWORD\": os.getenv(\"VECTOR_STORE_PASSWORD\"),\n",
    "    \"INDEX_NAME\": os.getenv(\"INDEX_NAME\"),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_CREATING THE ENDPOINT WHERE THE MODEL WILL BE DEPLOYED_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x147717891b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = \"aml-langchain-\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "endpoint_name = endpoint_name + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(name=endpoint_name, auth_mode=\"key\")\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SETTING UP DEPLOYMENT PARAMETERS_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_NAME = \"aml-langchain-deployment\"\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    environment_variables={\n",
    "        **openai_env_vars,\n",
    "        **acs_env_vars,\n",
    "    },\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_DEPLOYING TO THE ENDPOINT_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint aml-langchain-07191453558955 exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x147778ff1c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................."
     ]
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(deployment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_UPDATING TRAFFIC TO THE ENDPOINT_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x14777912380>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic = {DEPLOYMENT_NAME: 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TESTING THE RESULTS_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\" The president said that she is a Circuit Court of Appeals Judge and one of our nation\\\\u2019s top legal minds who will continue Justice Breyer\\\\u2019s legacy of excellence.\"]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    request_file=\"request.json\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml-rag-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
