{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MLFlow model locally and try predictions\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. You need to have run successfully the training notebook related to this model, available in this same folder, where at the end of the notebook, after training the model, it downloads the 'artifacts' with the MLFlow model folder (\"./artifact_downloads/outputs/mlflow-model\").\n",
    "\n",
    "2. Create a conda environment with the 'conda.yaml' file provided within the \"mlflow-model\" folder, doing like the following:\n",
    "   1. if you are running this notebook on a windows machine, Please remove \"Pycocotools\" and \"recordclass\" lines from conda.yaml and have c++ build tools( https://visualstudio.microsoft.com/visual-cpp-build-tools/ ) installed before running the below steps\n",
    "\n",
    "   1. (base) /> conda env create --file conda.yaml --name automl-model-image-multicls-cls-env\n",
    "   \n",
    "   1. (base) /> conda activate automl-model-image-multicls-cls-env\n",
    "   \n",
    "   1. (automl-model-image-multicls-cls-env) /> conda install jupyter nb_conda\n",
    "\n",
    "3. Run Jupyter and make sure you are using the related 'automl-model-image-multicls-cls-env' Kernel.\n",
    "\n",
    "4. Run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the MLFlow model files were downloaded successfully by the training notebook, you should see the files here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Local dir where you have downloaded and saved the artifacts\n",
    "local_dir = \"./\"\n",
    "\n",
    "mlflow_model_dir = os.path.join(local_dir, \"blip\")\n",
    "\n",
    "# Show the contents of the MLFlow model folder\n",
    "os.listdir(mlflow_model_dir)\n",
    "\n",
    "# You should see a list of files such as the following:\n",
    "# ['artifacts', 'conda.yaml', 'MLmodel', 'python_env.yaml', 'python_model.pkl', 'requirements.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to a different location if you downloaded data at a different location\n",
    "dataset_parent_dir = \"./data\"\n",
    "dataset_name = \"fridgeObjects\"\n",
    "\n",
    "os.listdir(os.path.join(dataset_parent_dir, dataset_name, \"milk_bottle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data into a Pandas DataFrame\n",
    "\n",
    "Load some test images into a Pandas DataFrame in order to try some predictions with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = [\n",
    "    os.path.join(dataset_parent_dir, dataset_name, \"can\", \"1.jpg\"),\n",
    "    os.path.join(dataset_parent_dir, dataset_name, \"carton\", \"33.jpg\"),\n",
    "    os.path.join(dataset_parent_dir, dataset_name, \"milk_bottle\", \"99.jpg\"),\n",
    "    os.path.join(dataset_parent_dir, dataset_name, \"water_bottle\", \"120.jpg\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare sample data for image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "images = [\n",
    "    base64.encodebytes(read_image(image_path)).decode('utf-8')\n",
    "    for image_path in test_image_paths\n",
    "]\n",
    "image_data = [[img, \"\"] for img in images]\n",
    "test_df_image = pd.DataFrame(\n",
    "    data=image_data,\n",
    "    columns=[\"image\", \"text\"],\n",
    ")\n",
    "test_df_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare sample data for text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "text_list = [\n",
    "    \"text 1\", \"text 2\", \"text 3\", \"text 4\"\n",
    "]\n",
    "text_data = [[\"\", text] for text in text_list]\n",
    "test_df_text = pd.DataFrame(\n",
    "    data=text_data,\n",
    "    columns=[\"image\", \"text\"],\n",
    ")\n",
    "test_df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample data for image + text embeddings\n",
    "combine_data = [[images[i], text_list[i]] for i in range(0, len(image_data))]\n",
    "test_df_combine = pd.DataFrame(\n",
    "    data=combine_data,\n",
    "    columns=[\"image\", \"text\"],\n",
    ")\n",
    "test_df_combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best model in memory\n",
    "\n",
    "Load the model using MLflow flavor. Check MLmodel under the downloaded folder (artifact_downloads/outputs/mlflow-model). For this particular example (and for AutoML for Images scenario), MLmodel file will describe python_function flavor. We show how to load model using pyfunc flavor. For more information on MLflow flavors, visit: https://www.mlflow.org/docs/latest/models.html#storage-format\n",
    "\n",
    "Loading the models locally assume that you are running the notebook in an environment compatible with the model. The list of dependencies that is expected by the model is specified in the MLFlow model produced by AutoML (in the 'conda.yaml' file within the mlflow-model folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(mlflow_model_dir,\"code\"))\n",
    "from clip_embeddings_mlflow_wrapper import CLIPEmbeddingsMLFlowModelWrapper\n",
    "mlflow_model_wrapper = CLIPEmbeddingsMLFlowModelWrapper(task_type=\"embeddings\")\n",
    "import pickle\n",
    "with open(os.path.join(mlflow_model_dir,\"python_model.pkl\"), 'wb') as f:\n",
    "    pickle.dump(mlflow_model_wrapper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "# Way #1: Get the MLFlow model from the downloaded MLFlow model files\n",
    "pyfunc_model = mlflow.pyfunc.load_model(mlflow_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image embeddings\n",
    "result = pyfunc_model.predict(test_df_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text embeddings\n",
    "result = pyfunc_model.predict(test_df_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get combined embeddings\n",
    "result = pyfunc_model.predict(test_df_combine)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test invalid input handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_invalid = test_df_combine.copy()\n",
    "\n",
    "# test_df_invalid['text'].iloc[0] = \"\" # some text but not all\n",
    "\n",
    "# test_df_invalid['image'].iloc[0] = \"\" # some image but not all\n",
    "\n",
    "# empty dataframe\n",
    "test_df_invalid['image'].iloc[0:4] = \"\"\n",
    "test_df_invalid['text'].iloc[0:4] = \"\"\n",
    "\n",
    "test_df_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get combined embeddings\n",
    "result = pyfunc_model.predict(test_df_invalid)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "rc_133",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
