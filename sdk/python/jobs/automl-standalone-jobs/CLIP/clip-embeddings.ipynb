{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MLFlow model locally and try predictions\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. You need to have run successfully the training notebook related to this model, available in this same folder, where at the end of the notebook, after training the model, it downloads the 'artifacts' with the MLFlow model folder (\"./artifact_downloads/outputs/mlflow-model\").\n",
    "\n",
    "2. Create a conda environment with the 'conda.yaml' file provided within the \"mlflow-model\" folder, doing like the following:\n",
    "   1. if you are running this notebook on a windows machine, Please remove \"Pycocotools\" and \"recordclass\" lines from conda.yaml and have c++ build tools( https://visualstudio.microsoft.com/visual-cpp-build-tools/ ) installed before running the below steps\n",
    "\n",
    "   1. (base) /> conda env create --file conda.yaml --name automl-model-image-multicls-cls-env\n",
    "   \n",
    "   1. (base) /> conda activate automl-model-image-multicls-cls-env\n",
    "   \n",
    "   1. (automl-model-image-multicls-cls-env) /> conda install jupyter nb_conda\n",
    "\n",
    "3. Run Jupyter and make sure you are using the related 'automl-model-image-multicls-cls-env' Kernel.\n",
    "\n",
    "4. Run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the MLFlow model files were downloaded successfully by the training notebook, you should see the files here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts',\n",
       " 'code',\n",
       " 'conda.yaml',\n",
       " 'LICENSE',\n",
       " 'MLmodel',\n",
       " 'python_env.yaml',\n",
       " 'python_model.pkl',\n",
       " 'train_label_list.npy']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Local dir where you have downloaded and saved the artifacts\n",
    "local_dir = \"./\"\n",
    "\n",
    "mlflow_model_dir = os.path.join(local_dir, \"clip-embeddings-mlflow\")\n",
    "\n",
    "# Show the contents of the MLFlow model folder\n",
    "os.listdir(mlflow_model_dir)\n",
    "\n",
    "# You should see a list of files such as the following:\n",
    "# ['artifacts', 'conda.yaml', 'MLmodel', 'python_env.yaml', 'python_model.pkl', 'requirements.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100.jpg',\n",
       " '101.jpg',\n",
       " '65.jpg',\n",
       " '66.jpg',\n",
       " '67.jpg',\n",
       " '68.jpg',\n",
       " '69.jpg',\n",
       " '70.jpg',\n",
       " '71.jpg',\n",
       " '72.jpg',\n",
       " '73.jpg',\n",
       " '74.jpg',\n",
       " '75.jpg',\n",
       " '76.jpg',\n",
       " '77.jpg',\n",
       " '78.jpg',\n",
       " '79.jpg',\n",
       " '80.jpg',\n",
       " '81.jpg',\n",
       " '82.jpg',\n",
       " '83.jpg',\n",
       " '84.jpg',\n",
       " '85.jpg',\n",
       " '86.jpg',\n",
       " '87.jpg',\n",
       " '88.jpg',\n",
       " '89.jpg',\n",
       " '90.jpg',\n",
       " '91.jpg',\n",
       " '92.jpg',\n",
       " '93.jpg',\n",
       " '94.jpg',\n",
       " '95.jpg',\n",
       " '96.jpg',\n",
       " '97.jpg',\n",
       " '98.jpg',\n",
       " '99.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to a different location if you downloaded data at a different location\n",
    "dataset_parent_dir = \"./data\"\n",
    "dataset_name = \"fridgeObjects\"\n",
    "\n",
    "os.listdir(os.path.join(dataset_parent_dir, dataset_name, \"milk_bottle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data into a Pandas DataFrame\n",
    "\n",
    "Load some test images into a Pandas DataFrame in order to try some predictions with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = [\n",
    "    os.path.join(dataset_parent_dir, dataset_name, \"can\", \"1.jpg\"),\n",
    "    os.path.join(dataset_parent_dir, dataset_name, \"carton\", \"33.jpg\"),\n",
    "    os.path.join(dataset_parent_dir, dataset_name, \"milk_bottle\", \"99.jpg\"),\n",
    "    os.path.join(dataset_parent_dir, dataset_name, \"water_bottle\", \"120.jpg\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare sample data for image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQEASABIAAD/4XlnRXhpZgAASUkqAA...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQEASABIAAD/4XvwRXhpZgAASUkqAA...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQEASABIAAD/4aYSRXhpZgAASUkqAA...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQEASABIAAD/4Y+MRXhpZgAASUkqAA...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image text\n",
       "0  /9j/4AAQSkZJRgABAQEASABIAAD/4XlnRXhpZgAASUkqAA...     \n",
       "1  /9j/4AAQSkZJRgABAQEASABIAAD/4XvwRXhpZgAASUkqAA...     \n",
       "2  /9j/4AAQSkZJRgABAQEASABIAAD/4aYSRXhpZgAASUkqAA...     \n",
       "3  /9j/4AAQSkZJRgABAQEASABIAAD/4Y+MRXhpZgAASUkqAA...     "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "images = [\n",
    "    base64.encodebytes(read_image(image_path)).decode('utf-8')\n",
    "    for image_path in test_image_paths\n",
    "]\n",
    "image_data = [[img, \"\"] for img in images]\n",
    "test_df_image = pd.DataFrame(\n",
    "    data=image_data,\n",
    "    columns=[\"image\", \"text\"],\n",
    ")\n",
    "test_df_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare sample data for text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>text 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>text 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>text 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>text 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image    text\n",
       "0        text 1\n",
       "1        text 2\n",
       "2        text 3\n",
       "3        text 4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "text_list = [\n",
    "    \"text 1\", \"text 2\", \"text 3\", \"text 4\"\n",
    "]\n",
    "text_data = [[\"\", text] for text in text_list]\n",
    "test_df_text = pd.DataFrame(\n",
    "    data=text_data,\n",
    "    columns=[\"image\", \"text\"],\n",
    ")\n",
    "test_df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQEASABIAAD/4XlnRXhpZgAASUkqAA...</td>\n",
       "      <td>text 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQEASABIAAD/4XvwRXhpZgAASUkqAA...</td>\n",
       "      <td>text 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQEASABIAAD/4aYSRXhpZgAASUkqAA...</td>\n",
       "      <td>text 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQEASABIAAD/4Y+MRXhpZgAASUkqAA...</td>\n",
       "      <td>text 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image    text\n",
       "0  /9j/4AAQSkZJRgABAQEASABIAAD/4XlnRXhpZgAASUkqAA...  text 1\n",
       "1  /9j/4AAQSkZJRgABAQEASABIAAD/4XvwRXhpZgAASUkqAA...  text 2\n",
       "2  /9j/4AAQSkZJRgABAQEASABIAAD/4aYSRXhpZgAASUkqAA...  text 3\n",
       "3  /9j/4AAQSkZJRgABAQEASABIAAD/4Y+MRXhpZgAASUkqAA...  text 4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare sample data for image + text embeddings\n",
    "combine_data = [[images[i], text_list[i]] for i in range(0, len(image_data))]\n",
    "test_df_combine = pd.DataFrame(\n",
    "    data=combine_data,\n",
    "    columns=[\"image\", \"text\"],\n",
    ")\n",
    "test_df_combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best model in memory\n",
    "\n",
    "Load the model using MLflow flavor. Check MLmodel under the downloaded folder (artifact_downloads/outputs/mlflow-model). For this particular example (and for AutoML for Images scenario), MLmodel file will describe python_function flavor. We show how to load model using pyfunc flavor. For more information on MLflow flavors, visit: https://www.mlflow.org/docs/latest/models.html#storage-format\n",
    "\n",
    "Loading the models locally assume that you are running the notebook in an environment compatible with the model. The list of dependencies that is expected by the model is specified in the MLFlow model produced by AutoML (in the 'conda.yaml' file within the mlflow-model folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./clip-embeddings-mlflow/code/')\n",
    "from mlflow_wrapper import CLIPMLFlowModelWrapper\n",
    "mlflow_model_wrapper = CLIPMLFlowModelWrapper(task_type=\"zero-shot-image-classification\")\n",
    "import pickle\n",
    "with open('./mlflow-model-pyfunc-folder/python_model.pkl', 'wb') as f:\n",
    "    pickle.dump(mlflow_model_wrapper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "# Way #1: Get the MLFlow model from the downloaded MLFlow model files\n",
    "pyfunc_model = mlflow.pyfunc.load_model(mlflow_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_features</th>\n",
       "      <th>text_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.04559585452079773, 0.48873665928840637, 0....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.24213312566280365, -0.410836398601532, 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.23669609427452087, -0.043139100074768066, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.11363381147384644, 0.29685330390930176, 0....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image_features text_features\n",
       "0  [-0.04559585452079773, 0.48873665928840637, 0....           NaN\n",
       "1  [-0.24213312566280365, -0.410836398601532, 0.0...           NaN\n",
       "2  [-0.23669609427452087, -0.043139100074768066, ...           NaN\n",
       "3  [-0.11363381147384644, 0.29685330390930176, 0....           NaN"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get image embeddings\n",
    "result = pyfunc_model.predict(test_df_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_features</th>\n",
       "      <th>text_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.11739224940538406, 0.4197632968425751, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.12335444986820221, 0.37793639302253723, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.09359746426343918, 0.39012327790260315, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.0883416086435318, 0.4281783103942871, -0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_features                                      text_features\n",
       "0            NaN  [-0.11739224940538406, 0.4197632968425751, -0....\n",
       "1            NaN  [-0.12335444986820221, 0.37793639302253723, -0...\n",
       "2            NaN  [-0.09359746426343918, 0.39012327790260315, -0...\n",
       "3            NaN  [-0.0883416086435318, 0.4281783103942871, -0.1..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get text embeddings\n",
    "result = pyfunc_model.predict(test_df_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_features</th>\n",
       "      <th>text_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.04559585452079773, 0.48873665928840637, 0....</td>\n",
       "      <td>[-0.11739224940538406, 0.4197632968425751, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.24213312566280365, -0.410836398601532, 0.0...</td>\n",
       "      <td>[-0.12335444986820221, 0.37793639302253723, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.23669609427452087, -0.043139100074768066, ...</td>\n",
       "      <td>[-0.09359746426343918, 0.39012327790260315, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.11363381147384644, 0.29685330390930176, 0....</td>\n",
       "      <td>[-0.0883416086435318, 0.4281783103942871, -0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image_features  \\\n",
       "0  [-0.04559585452079773, 0.48873665928840637, 0....   \n",
       "1  [-0.24213312566280365, -0.410836398601532, 0.0...   \n",
       "2  [-0.23669609427452087, -0.043139100074768066, ...   \n",
       "3  [-0.11363381147384644, 0.29685330390930176, 0....   \n",
       "\n",
       "                                       text_features  \n",
       "0  [-0.11739224940538406, 0.4197632968425751, -0....  \n",
       "1  [-0.12335444986820221, 0.37793639302253723, -0...  \n",
       "2  [-0.09359746426343918, 0.39012327790260315, -0...  \n",
       "3  [-0.0883416086435318, 0.4281783103942871, -0.1...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get combined embeddings\n",
    "result = pyfunc_model.predict(test_df_combine)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test invalid input handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image text\n",
       "0           \n",
       "1           \n",
       "2           \n",
       "3           "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_invalid = test_df_combine.copy()\n",
    "\n",
    "# test_df_invalid['text'].iloc[0] = \"\" # some text but not all\n",
    "\n",
    "# test_df_invalid['image'].iloc[0] = \"\" # some image but not all\n",
    "\n",
    "# empty dataframe\n",
    "test_df_invalid['image'].iloc[0:4] = \"\"\n",
    "test_df_invalid['text'].iloc[0:4] = \"\"\n",
    "\n",
    "test_df_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text and image columns are empty\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\rbhimani\\AppData\\Local\\Temp\\ipykernel_26512\\2696827253.py\", line 2, in <module>\n",
      "    result = pyfunc_model.predict(test_df_invalid)\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py\", line 427, in predict\n",
      "    return self._predict_fn(data)\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\mlflow\\pyfunc\\model.py\", line 365, in predict\n",
      "    return self.python_model.predict(self.context, self._convert_input(model_input))\n",
      "  File \"C:\\Users\\rbhimani\\Desktop\\azureml-examples\\sdk\\python\\jobs\\automl-standalone-jobs\\CLIP\\clip-embeddings-mlflow\\code\\mlflow_wrapper.py\", line 68, in predict\n",
      "    has_images, has_text = self.validate_input(input_data)\n",
      "  File \"C:\\Users\\rbhimani\\Desktop\\azureml-examples\\sdk\\python\\jobs\\automl-standalone-jobs\\CLIP\\clip-embeddings-mlflow\\code\\mlflow_wrapper.py\", line 167, in validate_input\n",
      "    raise\n",
      "RuntimeError: No active exception to reraise\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\rbhimani\\AppData\\Local\\anaconda3\\envs\\clip\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Get combined embeddings\n",
    "result = pyfunc_model.predict(test_df_invalid)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "rc_133",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
