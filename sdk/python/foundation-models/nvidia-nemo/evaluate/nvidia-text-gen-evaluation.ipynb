{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1700016896350
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting azure-ai-ml\n",
            "  Downloading azure_ai_ml-1.12.0-py3-none-any.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 5.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: azure-core<2.0.0,>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.26.4)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.17.3)\n",
            "Requirement already satisfied, skipping upgrade: pyjwt<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (2.4.0)\n",
            "Collecting azure-storage-file-share<13.0.0\n",
            "  Downloading azure_storage_file_share-12.15.0-py3-none-any.whl (267 kB)\n",
            "\u001b[K     |████████████████████████████████| 267 kB 109.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: azure-common<2.0.0,>=1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.1.28)\n",
            "Requirement already satisfied, skipping upgrade: isodate in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: opencensus-ext-azure<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.1.9)\n",
            "Requirement already satisfied, skipping upgrade: azure-storage-blob<13.0.0,>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (12.13.0)\n",
            "Requirement already satisfied, skipping upgrade: azure-mgmt-core<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.7.1)\n",
            "Collecting pydash<7.0.6,>=6.0.0\n",
            "  Downloading pydash-7.0.5-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 109.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.5\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.1 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting strictyaml<2.0.0\n",
            "  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 106.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.6.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (6.0)\n",
            "Collecting azure-storage-file-datalake<13.0.0\n",
            "  Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 101.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: colorama<0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.4.6)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.65.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.18.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (2.31.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.19.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-resources>=1.4.0; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (5.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pkgutil-resolve-name>=1.3.10; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (1.3.10)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (23.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-storage-file-share<13.0.0->azure-ai-ml) (38.0.4)\n",
            "Requirement already satisfied, skipping upgrade: opencensus<1.0.0,>=0.11.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (0.11.2)\n",
            "Requirement already satisfied, skipping upgrade: azure-identity<2.0.0,>=1.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (1.13.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.6.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (5.9.5)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (2022.9.24)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (23.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.26.16)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=3.1.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (3.12.0)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cryptography>=2.1.4->azure-storage-file-share<13.0.0->azure-ai-ml) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.11.0)\n",
            "Requirement already satisfied, skipping upgrade: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.1.3)\n",
            "Requirement already satisfied, skipping upgrade: msal<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.22.0)\n",
            "Requirement already satisfied, skipping upgrade: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-file-share<13.0.0->azure-ai-ml) (2.21)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<3.0dev,>=2.14.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.18.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.20.3)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.56.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.59.0)\n",
            "Requirement already satisfied, skipping upgrade: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.7.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.9)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (5.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.5.0)\n",
            "\u001b[31mERROR: azure-storage-file-share 12.15.0 has requirement azure-core<2.0.0,>=1.28.0, but you'll have azure-core 1.26.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pydash 7.0.5 has requirement typing-extensions!=4.6.0,>=3.10, but you'll have typing-extensions 4.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: azure-storage-file-datalake 12.14.0 has requirement azure-core<2.0.0,>=1.28.0, but you'll have azure-core 1.26.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: azure-storage-file-datalake 12.14.0 has requirement azure-storage-blob<13.0.0,>=12.19.0, but you'll have azure-storage-blob 12.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: azure-storage-file-share, pydash, marshmallow, strictyaml, azure-storage-file-datalake, azure-ai-ml\n",
            "Successfully installed azure-ai-ml-1.12.0 azure-storage-file-datalake-12.14.0 azure-storage-file-share-12.15.0 marshmallow-3.20.1 pydash-7.0.5 strictyaml-1.7.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting azure-identity\n",
            "  Downloading azure_identity-1.15.0-py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 6.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting msal<2.0.0,>=1.24.0\n",
            "  Downloading msal-1.25.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.3 MB/s s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: azure-core<2.0.0,>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity) (1.26.4)\n",
            "Requirement already satisfied, skipping upgrade: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cryptography>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity) (38.0.4)\n",
            "Requirement already satisfied, skipping upgrade: PyJWT[crypto]<3,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal<2.0.0,>=1.24.0->azure-identity) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal<2.0.0,>=1.24.0->azure-identity) (2.31.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=4.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity) (4.6.0)\n",
            "Requirement already satisfied, skipping upgrade: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.7.0)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cryptography>=2.5->azure-identity) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.24.0->azure-identity) (1.26.16)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.24.0->azure-identity) (2022.9.24)\n",
            "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.24.0->azure-identity) (3.4)\n",
            "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.24.0->azure-identity) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\n",
            "\u001b[31mERROR: azureml-inference-server-http 0.8.4 has requirement flask<2.3.0, but you'll have flask 2.3.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: azure-cli 2.49.0 has requirement azure-keyvault-keys==4.8.0b2, but you'll have azure-keyvault-keys 4.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: azure-cli 2.49.0 has requirement azure-mgmt-keyvault==10.2.0, but you'll have azure-mgmt-keyvault 10.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: azure-cli 2.49.0 has requirement azure-mgmt-resource==22.0.0, but you'll have azure-mgmt-resource 21.1.0b1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: azure-cli-core 2.49.0 has requirement msal[broker]==1.20.0, but you'll have msal 1.25.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: msal, azure-identity\n",
            "  Attempting uninstall: msal\n",
            "    Found existing installation: msal 1.22.0\n",
            "    Uninstalling msal-1.22.0:\n",
            "      Successfully uninstalled msal-1.22.0\n",
            "  Attempting uninstall: azure-identity\n",
            "    Found existing installation: azure-identity 1.13.0\n",
            "    Uninstalling azure-identity-1.13.0:\n",
            "      Successfully uninstalled azure-identity-1.13.0\n",
            "Successfully installed azure-identity-1.15.0 msal-1.25.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting datasets==2.9.0\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 7.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (23.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (1.21.6)\n",
            "Requirement already satisfied, skipping upgrade: pyarrow>=6.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (9.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.62.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (4.65.0)\n",
            "Requirement already satisfied, skipping upgrade: responses<0.19 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (0.18.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (2.31.0)\n",
            "Requirement already satisfied, skipping upgrade: aiohttp in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (3.8.4)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (6.0)\n",
            "Requirement already satisfied, skipping upgrade: huggingface-hub<1.0.0,>=0.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: fsspec[http]>=2021.11.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (2023.5.0)\n",
            "Requirement already satisfied, skipping upgrade: multiprocess in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (0.70.14)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3.7 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (0.3.6)\n",
            "Requirement already satisfied, skipping upgrade: xxhash in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from datasets==2.9.0) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->datasets==2.9.0) (2022.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->datasets==2.9.0) (2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.25.10 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from responses<0.19->datasets==2.9.0) (1.26.16)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.9.0) (2022.9.24)\n",
            "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.9.0) (3.4)\n",
            "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.9.0) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->datasets==2.9.0) (23.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Prequisites\n",
        "\n",
        "%pip install --upgrade azure-ai-ml\n",
        "%pip install --upgrade azure-identity\n",
        "%pip install --upgrade datasets==2.9.0\n",
        "%pip install py7zr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700016814248
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml.entities import AmlCompute\n",
        "import time\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "workspace_ml_client = None\n",
        "try:\n",
        "    workspace_ml_client = MLClient.from_config(credential)\n",
        "    subscription_id = workspace_ml_client.subscription_id\n",
        "    workspace = workspace_ml_client.workspace_name\n",
        "    resource_group = workspace_ml_client.resource_group_name\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    # Enter details of your AML workspace\n",
        "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "    resource_group = \"<RESOURCE_GROUP>\"\n",
        "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
        "    workspace_ml_client = MLClient(\n",
        "        credential, subscription_id, resource_group, workspace\n",
        "    )\n",
        "\n",
        "# replace with the registry name\n",
        "nemo_registry = \"nvidia-ai\" \n",
        "\n",
        "nemo_registry_ml_client = MLClient(\n",
        "    credential, subscription_id, resource_group, registry_name=nemo_registry\n",
        ")\n",
        "\n",
        "nemo_registry_ml_client"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Creating Computes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700018891994
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# If you already have a gpu cluster, mention it here. Else will create a new one with the name 'ghyadav-westus-a100'\n",
        "# model will only run on an a100 instance\n",
        "\n",
        "compute_cluster = \"do-not-delete-nvidia-testing\"\n",
        "\n",
        "try:\n",
        "    compute = workspace_ml_client.compute.get(compute_cluster)\n",
        "    print(f\"GPU compute '{compute_cluster}' found.\")\n",
        "except Exception as ex:\n",
        "    print(f\"GPU compute '{compute_cluster}' not found. Creating new one.\")\n",
        "    compute = AmlCompute(\n",
        "        name=compute_cluster,\n",
        "        size=\"STANDARD_ND96AMSR_A100_V4\",\n",
        "        max_instances=2,  # For multi node training set this to an integer value more than 1\n",
        "    )\n",
        "    workspace_ml_client.compute.begin_create_or_update(compute).wait()\n",
        "\n",
        "# generating a unique timestamp that can be used for names and versions that need to be unique\n",
        "timestamp = str(int(time.time()))\n",
        "\n",
        "\n",
        "# This is the number of GPUs in a single node of the selected 'vm_size' compute.\n",
        "# Setting this to less than the number of GPUs will result in underutilized GPUs, taking longer to train.\n",
        "# Setting this to more than the number of GPUs will result in an error.\n",
        "\n",
        "gpus_per_node = 1  # default value\n",
        "gpu_count_found = False\n",
        "ws_computes = workspace_ml_client.compute.list_sizes()\n",
        "for ws_compute in ws_computes:\n",
        "    if ws_compute.name.lower() == compute.size.lower():\n",
        "        gpus_per_node = ws_compute.gpus\n",
        "        print(f\"Number of GPUs in compute {ws_compute.name} are {ws_compute.gpus}\")\n",
        "# if gpu_count_found not found, then print an error\n",
        "if gpus_per_node > 0:\n",
        "    gpu_count_found = True\n",
        "else:\n",
        "    gpu_count_found = False\n",
        "    print(f\"No GPUs found in compute. Number of GPUs in compute {compute.size} 0.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Input Data for Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700021765687
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# download the dataset using the helper script. This needs datasets library: https://pypi.org/project/datasets/\n",
        "import os\n",
        "from datasets import load_dataset, get_dataset_split_names\n",
        "dataset_dir = \"samsum-dataset\"\n",
        "dataset_name = \"samsum\"\n",
        "# create the download directory if it does not exist\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "\n",
        "\n",
        "# import hugging face datasets library\n",
        "\n",
        "split = 'test'\n",
        "dataset = load_dataset( dataset_name, split=split)\n",
        "# save the split of the dataset to the download directory as json lines file\n",
        "dataset.to_json(os.path.join(dataset_dir, f\"{split}.jsonl\"))\n",
        "# print dataset features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700021773282
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "evaluation_dataset = \"./samsum-dataset/test.jsonl\"\n",
        "pd.set_option(\n",
        "    \"display.max_colwidth\", 0\n",
        ")  # set the max column width to 0 to display the full text\n",
        "df = pd.read_json(\"./samsum-dataset/test.jsonl\", lines=True)\n",
        "df = df[['dialogue']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700021784720
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "frac = 0.01\n",
        "evaluation_dataset_frac = \"./samsum-dataset/test/test_frac.jsonl\"\n",
        "os.makedirs(\"./samsum-dataset/test\", exist_ok=True)\n",
        "df.sample(frac=frac).to_json(\n",
        "    evaluation_dataset_frac, orient=\"records\", lines=True\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Loading model from Registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700020630465
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model_name = \"Nemotron-3-8B-Base-4k\"\n",
        "model_version = \"latest\"\n",
        "\n",
        "nemo_model_object = nemo_registry_ml_client.models.get(model_name, label=\"latest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700021668795
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "nemo_model_object"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700018241647
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = \"Summarize this dialog:\\n{prompt}\\n---\\nSummary:\\n\"\n",
        "prompt_path = \"prompt.txt\"\n",
        "with open(prompt_path, \"w\") as f:\n",
        "    f.write(prompt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Submitting Evaluation Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700022099970
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# fetch the pipeline component\n",
        "pipeline_component_func = nemo_registry_ml_client.components.get(\n",
        "    name=\"nemo_text_generation_evaluation\", label=\"latest\"\n",
        ")\n",
        "\n",
        "\n",
        "# define the pipeline job\n",
        "@pipeline()\n",
        "def evaluation_pipeline(mlflow_model):\n",
        "    evaluation_job = pipeline_component_func(\n",
        "        dataset_path=Input(type=AssetTypes.URI_FOLDER, path=\"./samsum-dataset/test/\"),\n",
        "        model_path=Input(type=AssetTypes.TRITON_MODEL, path=f\"{nemo_model_object.id}\"),\n",
        "        prompt_schema=Input(type=AssetTypes.URI_FILE, path=prompt_path),\n",
        "    )\n",
        "    return {\"evaluation_result\": evaluation_job.outputs.evaluation_result}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700021439682
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "experiment_name = \"nemo-text-gen-eval-pipeline\"\n",
        "pipeline_jobs = []\n",
        "\n",
        "pipeline_object = evaluation_pipeline()\n",
        "\n",
        "# don't reuse cached results from previous jobs\n",
        "pipeline_object.settings.force_rerun = True\n",
        "pipeline_object.settings.default_compute = compute_cluster\n",
        "pipeline_job = workspace_ml_client.jobs.create_or_update(\n",
        "    pipeline_object, experiment_name=experiment_name\n",
        ")\n",
        "# add model['name'] and pipeline_job.name as key value pairs to a dictionary\n",
        "pipeline_jobs.append({\"model_name\": model_name, \"job_name\": pipeline_job.name})\n",
        "# wait for the pipeline job to complete\n",
        "workspace_ml_client.jobs.stream(pipeline_job.name)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
