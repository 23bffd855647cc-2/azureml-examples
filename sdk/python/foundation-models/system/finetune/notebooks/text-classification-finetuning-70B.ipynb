{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae56335a",
   "metadata": {},
   "source": [
    "# Finetuning Llama-2 on Azure Machine Mearning\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Set up the environment](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Establish baseline](#Baseline)\n",
    "1. [Finetune](#Finetune)\n",
    "1. [Evaluate](#Evaluate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "873a7cc4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates finetuning Llama-2 foundation model on a text classification dataset using AzureML.\n",
    "\n",
    "Llama-2 model is now available in AzureML Model Catalog. For details please see the [blog](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/introducing-llama-2-on-azure/ba-p/3881233).\n",
    "\n",
    "This functionality is in public preview in Azure Machine Learning. The preview version is provided without a service level agreement, and itâ€™s not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews.\n",
    "\n",
    "Notebook summary:\n",
    "\n",
    "1. Setting the environment\n",
    "2. Loading the model and data. In this example we use the [20 Newsgroups dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)\n",
    "3. Evaluate the pretrained model on the test set to establish baseline metrics\n",
    "4. Finetune the model\n",
    "5. Evaluating the finetuned model on a test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a7a966e",
   "metadata": {},
   "source": [
    "## Set up the environment <a class=\"anchor\" id=\"Setup\"></a>\n",
    "\n",
    "Install and load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44210d88",
   "metadata": {
    "gather": {
     "logged": 1690422784786
    }
   },
   "outputs": [],
   "source": [
    "! pip uninstall -y azure-identity\n",
    "! pip uninstall -y azure-ai-ml\n",
    "\n",
    "! pip install -U azure-identity\n",
    "! pip install azure-ai-ml==1.9.0a20230616001 --extra-index-url https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/\n",
    "!pip install torch==2.0.1\n",
    "!pip install bitsandbytes\n",
    "!pip install transformers==4.31.0\n",
    "!pip install peft\n",
    "!pip install azureml-evaluate-mlflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1833f26f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae5aa0",
   "metadata": {
    "gather": {
     "logged": 1690422788582
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import LlamaTokenizerFast, LlamaForCausalLM, LlamaTokenizer, LlamaForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from azureml.metrics import compute_metrics, constants\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6f5e85b",
   "metadata": {},
   "source": [
    "### Download model from azureml-meta registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a21767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    "    ClientSecretCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "import time\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# connect to a workspace\n",
    "workspace_ml_client = None\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential)\n",
    "    subscription_id = workspace_ml_client.subscription_id\n",
    "    workspace = workspace_ml_client.workspace_name\n",
    "    resource_group = workspace_ml_client.resource_group_name\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCS_GROUP>\"\n",
    "    workspace = \"<WORKSPACE_NAME>\"\n",
    "    workspace_ml_client = MLClient(\n",
    "        credential, subscription_id, resource_group, workspace\n",
    "    )\n",
    "# Connect to the meta  registry\n",
    "registry_mlclient = MLClient(credential=credential, registry_name=\"azureml-meta\")\n",
    "model_name = \"Llama-2-70b\"\n",
    "version = list(registry_mlclient.models.list(model_name))[0].version\n",
    "registry_mlclient.models.download(model_name, version=version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "576c2f6f",
   "metadata": {},
   "source": [
    "### Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original tokenizer\n",
    "tokenizer_path = f'{model_name}/mlflow_model_folder/data/tokenizer'\n",
    "tokenizer = LlamaTokenizer.from_pretrained(tokenizer_path)\n",
    "tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2f500",
   "metadata": {
    "gather": {
     "logged": 1690424906644
    }
   },
   "outputs": [],
   "source": [
    "# Load original model\n",
    "model_path = f'{model_name}/mlflow_model_folder/data/model'\n",
    "model = LlamaForSequenceClassification.from_pretrained(model_path, device_map='auto', load_in_8bit=True, torch_dtype=torch.float16, num_labels=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cf1f5e5",
   "metadata": {},
   "source": [
    "### Load and prepare data \n",
    "We use the 20-Newsgroup dataset from scikit-learn. We subsample the dataset to select only 4 categories (classes), and sample a 200-row training set, and a 100-row test set which will be held out for model evaluation. (Not that after removing some missing label rows, the exact number of rows are slightly smaller.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34469c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"text-dnn-data\"  # Local directory to store data\n",
    "# blobstore_datadir = data_dir  # Blob store directory to store data in\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "target_column_name = \"label\"\n",
    "feature_column_name = \"sentence\"\n",
    "\n",
    "\n",
    "def get_20newsgroups_data():\n",
    "    \"\"\"Fetches 20 Newsgroups data from scikit-learn\n",
    "    Returns them in form of pandas dataframes\n",
    "    \"\"\"\n",
    "    remove = (\"headers\", \"footers\", \"quotes\")\n",
    "    categories = [\n",
    "        \"rec.sport.baseball\",\n",
    "        \"rec.sport.hockey\",\n",
    "        \"comp.graphics\",\n",
    "        \"sci.space\",\n",
    "    ]\n",
    "\n",
    "    data = fetch_20newsgroups(\n",
    "        subset=\"train\",\n",
    "        categories=categories,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=remove,\n",
    "    )\n",
    "    data = pd.DataFrame(\n",
    "        {feature_column_name: data.data, target_column_name: data.target}\n",
    "    )\n",
    "\n",
    "    data_train = data[:200]\n",
    "    data_test = data[200:300]\n",
    "\n",
    "    data_train = remove_blanks_20news(\n",
    "        data_train, feature_column_name, target_column_name\n",
    "    )\n",
    "    data_test = remove_blanks_20news(data_test, feature_column_name, target_column_name)\n",
    "    return Dataset.from_pandas(data_train), Dataset.from_pandas(data_test)\n",
    "\n",
    "\n",
    "def remove_blanks_20news(data, feature_column_name, target_column_name):\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        data.at[index, feature_column_name] = (\n",
    "            row[feature_column_name].replace(\"\\n\", \" \").strip()\n",
    "        )\n",
    "\n",
    "    data = data[data[feature_column_name] != \"\"]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9701254",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = get_20newsgroups_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb90295",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c030a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2678209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    outputs = tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_train.map(\n",
    "    lambda samples: tokenize(samples), remove_columns=[\"__index_level_0__\", \"sentence\"], load_from_cache_file=False)\n",
    "\n",
    "validation_dataset = data_test.map(\n",
    "    lambda samples: tokenize(samples), remove_columns=[\"__index_level_0__\", \"sentence\"], load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation_dataset[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4bd5f56",
   "metadata": {},
   "source": [
    "## Evaluate the pretrained model <a class=\"anchor\" id=\"Baseline\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2be09247",
   "metadata": {},
   "source": [
    "### Compte metrics on test data to establish baseline\n",
    "We use azureml-metrics package, which is in preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885174ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test dataset\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52858cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Computation\n",
    "device = \"cuda\"\n",
    "l = len(validation_dataset)\n",
    "batch_size = 1\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for i in range(0, 4, batch_size):\n",
    "    print('Processing: ', i)\n",
    "    data_batch = validation_dataset[i:i + batch_size]\n",
    "    # NOTE: Before passing data_batch['input_ids] to the model, cast them using torch.LongTensor()\n",
    "    # Same for data_batch['attention_mask']. So that .to(device) call can work.\n",
    "    #print(data_batch)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=torch.LongTensor(data_batch['input_ids']).to(device), \n",
    "                        attention_mask=torch.LongTensor(data_batch['attention_mask']).to(device))\n",
    "    batch_predictions = outputs.logits.argmax(dim=-1)\n",
    "    batch_predictions, batch_references = batch_predictions.detach().cpu().numpy().tolist(), data_batch[\"label\"]\n",
    "    predictions.extend(batch_predictions)\n",
    "    references.extend(batch_references)\n",
    "\n",
    "print(predictions)\n",
    "print(references)\n",
    "\n",
    "#Compute metrics\n",
    "metrics = compute_metrics(task_type=constants.Tasks.CLASSIFICATION,\n",
    "                          y_test=predictions,\n",
    "                          y_pred=references)[\"metrics\"]\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe0aa4",
   "metadata": {
    "gather": {
     "logged": 1690424906849
    }
   },
   "outputs": [],
   "source": [
    "model.hf_device_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d7a85a3",
   "metadata": {},
   "source": [
    "## Finetune the model <a class=\"anchor\" id=\"Finetune\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b2161",
   "metadata": {
    "gather": {
     "logged": 1690424907123
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f1740",
   "metadata": {
    "gather": {
     "logged": 1690424936083
    }
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "   r=4,\n",
    "   lora_alpha=16,\n",
    "   target_modules= [\n",
    "       \"q_proj\",\n",
    "       \"v_proj\",\n",
    "   ],\n",
    "   lora_dropout=.05,\n",
    "   bias=\"none\",\n",
    "   task_type=\"SEQ_CLS\", # use this to get the task type: https://github.com/huggingface/peft/blob/96c0277a1b9a381b10ab34dbf84917f9b3b992e6/src/peft/utils/config.py#L38\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccc08c",
   "metadata": {
    "gather": {
     "logged": 1690424937704
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_steps=0,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=3e-4,\n",
    "    fp16=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    output_dir='.',\n",
    "    ddp_find_unused_parameters=None,\n",
    "    remove_unused_columns=False,\n",
    "    logging_steps=8)\n",
    "\n",
    "trainer = Trainer(\n",
    "                  model=peft_model,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=validation_dataset,\n",
    "                  args=training_args,\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b837e5",
   "metadata": {
    "gather": {
     "logged": 1690419249413
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e05e944",
   "metadata": {},
   "source": [
    "## Evaluate the finetuned model <a class=\"anchor\" id=\"Evaluate\"></a>\n",
    "Now that the finetuned model is ready, we compute accuracy metrics with it on the same test dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7407ad60",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f7c6f-4afe-43c9-a13a-17bec5a1f94b",
   "metadata": {
    "gather": {
     "logged": 1690419447246
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(validation_dataset)\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b3b15-b8b9-4ab3-aa91-dad01185b234",
   "metadata": {
    "gather": {
     "logged": 1690419447425
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673546a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3c3d2-72ba-4bd8-b7db-23f71ac44db7",
   "metadata": {
    "gather": {
     "logged": 1690419447869
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# import evaluate\n",
    "# metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "# metric.compute(predictions=preds, references=predictions.label_ids)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions.label_ids, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94421293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test dataset\n",
    "peft_model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26dd3a0a",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07788b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Computation\n",
    "device = \"cuda\"\n",
    "l = len(validation_dataset)\n",
    "batch_size = 1\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for i in range(0, 4, batch_size):\n",
    "    print('Processing: ', i)\n",
    "    data_batch = validation_dataset[i:i + batch_size]\n",
    "    # NOTE: Before passing data_batch['input_ids] to the model, cast them using torch.LongTensor()\n",
    "    # Same for data_batch['attention_mask']. So that .to(device) call can work.\n",
    "    #print(data_batch)\n",
    "    with torch.no_grad():\n",
    "        outputs = peft_model(input_ids=torch.LongTensor(data_batch['input_ids']).to(device), \n",
    "                             attention_mask=torch.LongTensor(data_batch['attention_mask']).to(device))\n",
    "    batch_predictions = outputs.logits.argmax(dim=-1)\n",
    "    batch_predictions, batch_references = batch_predictions.detach().cpu().numpy().tolist(), data_batch[\"label\"]\n",
    "    predictions.extend(batch_predictions)\n",
    "    references.extend(batch_references)\n",
    "\n",
    "print(predictions)\n",
    "print(references)\n",
    "\n",
    "#Compute metrics\n",
    "metrics = compute_metrics(task_type=constants.Tasks.CLASSIFICATION,\n",
    "                          y_test=predictions,\n",
    "                          y_pred=references)[\"metrics\"]\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f8adb56",
   "metadata": {},
   "source": [
    "## Comparison of metrics\n",
    "Here we see accuracy and other metrics improved before and after finetuning"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
